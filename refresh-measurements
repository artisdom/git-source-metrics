#!/usr/bin/env python

import os
import sys
import sets
import stat
import time
import shutil
import random
import pprint
import tempfile
import argparse
import datetime
import subprocess

SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
CONFIG_DIR = "~/.git-source-metrics/"
CODE_CACHE_DIR = "~/.git-source-metrics/code/"

def local_workingdir(git_url):
    code_cache_dir = os.path.expanduser(CODE_CACHE_DIR)
    if not os.path.exists(code_cache_dir):
        os.makedirs(code_cache_dir)
    working_dirname = filter(str.isalnum, git_url)
    working_dir_path = os.path.join(code_cache_dir, working_dirname)
    return working_dir_path

def spawn_git_fetcher(git_url):
    git_workdir = local_workingdir(git_url)
    if not os.path.exists(git_workdir):
        git_proc = subprocess.Popen("git clone %s %s" % (git_url, git_workdir), stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
    else:
        git_proc = subprocess.Popen("git fetch -q", stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=git_workdir, shell=True)
    return (git_url, git_proc)

# Launch one git process per repo (in parallel) to fetch the latest
# code and then wait for all the processes to finish.
def fetch_latest_code(all_git_urls):
    longest_git_url_length = max([len(git_url) for git_url in all_git_urls])
    remaining_procs = [spawn_git_fetcher(git_url) for git_url in all_git_urls]
    while len(remaining_procs) > 0:
        for (git_url, git_proc) in list(remaining_procs):
            git_proc.poll()
            if git_proc.returncode != None:
                remaining_procs.remove((git_url, git_proc))
                if git_proc.returncode == 0:
                    if not args.quiet:
                        print >> sys.stderr, "Finished fetching the latest code from repo: " + git_url.ljust(longest_git_url_length + 1),
                        print >> sys.stderr, " (still waiting for %d more git processes to finish)" % len(remaining_procs)
                else:
                    print >> sys.stderr, git_proc.stdout.read().strip()
                    print >> sys.stderr, git_proc.stderr.read().strip()
                    print >> sys.stderr, "ERROR: Failed (see error above) to fetch the latest code from repo: " + git_url.ljust(longest_git_url_length + 1),
                    print >> sys.stderr, " (still waiting for %d more git processes to finish)" % len(remaining_procs)
        time.sleep(1)

def git_reset_to(repo_name, git_workdir, sha1):
    if not args.quiet:
        print >> sys.stderr, "%s: git cleaning" % repo_name
    subprocess.check_call("git clean -dxff", cwd=git_workdir, shell=True)
    if not args.quiet:
        print >> sys.stderr, "%s: git resetting to %s" % (repo_name, sha1)
    subprocess.check_call("git reset -q --hard %s" % sha1, cwd=git_workdir, shell=True)

def get_sparse_commits(repo_name, repo_config):
    branch = "origin/" + repo_config.get("branch", "master")
    git_workdir = local_workingdir(repo_config["git_url"])
    git_log_cmd = "git log --first-parent --pretty=format:'%H %ct' " + branch
    git_log_output = subprocess.check_output(git_log_cmd, cwd=git_workdir, shell=True)
    sha1_and_timestamp_list = git_log_output.splitlines()

    all_xticks = {}
    last_tick_commit_date = datetime.datetime.utcfromtimestamp(0)

    while len(sha1_and_timestamp_list) > 0:
        sha1, timestamp = sha1_and_timestamp_list.pop(-1).split(" ", 1)
        if not timestamp:
            if not args.quiet:
                # Happens for 281a10c59d5a6522b2bebc6f78c165816d1f8421 in https://github.com/mozilla/gecko-dev
                # Not sure if this is a git bug or not, I couldn't find a way to create a commit with empty
                # author name (like the one above) so maybe it's a bug in the mercurial to git conversion tool
                # that mozilla uses.
                print "WARNING: commit with sha1 %s in repo %s looks invalid, ignoring." % (sha1, repo_name)
            continue
        commit_date = datetime.datetime.fromtimestamp(int(timestamp))
        if commit_date.year < args.ignore_commits_before_year:
            print "WARNING: commit with sha1 %s in repo %s is too old, ignoring." % (sha1, repo_name)
            continue
        if commit_date < last_tick_commit_date:
            if not args.quiet:
                print "WARNING: commit with sha1 %s in repo %s has commit date which is earlier than the commit date of its first parent, which is kind of weird; ignoring." % (sha1, repo_name)
            continue
        if not "tick_gap_days" in repo_config or (commit_date - last_tick_commit_date).days >= repo_config["tick_gap_days"]:
            all_xticks[timestamp] = sha1
            last_tick_commit_date = commit_date

    return all_xticks

def measure_metric(metric, git_workdir, sha1, timestamp):
    cmd_params_dict = {
        "sha1": sha1,
        "timestamp": timestamp,
    }
    metric_command = metric["cmd"] % cmd_params_dict
    if args.debug:
        print >>sys.stderr, "DEBUG: " + metric_command
    child_env = os.environ.copy()
    child_env["PATH"] = os.path.join(SCRIPT_DIR, "metric-scripts") + ":" + child_env["PATH"]
    value = subprocess.check_output(metric_command, cwd=git_workdir, env=child_env, shell=True).strip()
    if args.debug:
        print >>sys.stderr, "DEBUG: " + repr(value)
    return int(value)

class MeasuredData(object):
    def __init__(self):
        # datapoints is a dict in which repo_name   maps to a dict,
        #                      in which metric_name maps to a dict,
        #                      in which sha1        maps to a dict,
        #                      that contains "timestamp" and "value".
        self.datapoints = {}

    def load_from_file(self, filename):
        self.datapoints = eval(open(filename).read())

    def save_to_file(self, filename):
        string_data = pprint.pformat(self.datapoints)
        file_dir = os.path.dirname(filename)
        if not os.path.exists(file_dir):
            os.makedirs(file_dir)
        with open(filename, "w") as fil:
            fil.write(string_data + "\n")

    def clear_data_for_repo(self, repo_name):
        self.datapoints.pop(repo_name, None)

    def clear_data_for_repo_metric(self, repo_name, metric_name):
        repo_data = self.datapoints.get(repo_name)
        if repo_data:
            repo_data.pop(metric_name, None)

    def get_repo_metric_dict(self, repo_name, metric_name):
        return self.datapoints.setdefault(repo_name, {}).setdefault(metric_name, {})

    def is_measured(self, repo_name, sha1, metric_name):
        return sha1 in self.get_repo_metric_dict(repo_name, metric_name)

    def add_measurement(self, repo_name, sha1, timestamp, metric_name, value):
        metric_dict = self.get_repo_metric_dict(repo_name, metric_name)
        datapoint = {
            "timestamp": timestamp,
            "value": value,
        }
        metric_dict[sha1] = datapoint

def save_data_jscopy(config, selected_commits, measured_data, jsdata_filename):
    all_charts = config["charts"]
    all_metrics = config["metrics"]
    jsdata_tempfile_oshandle, jsdata_tempfile_name = tempfile.mkstemp()
    with open(jsdata_tempfile_name, "w") as jsdata_temp_file:
        jsdata_temp_file.write("all_chart_data = {\n")
        for chart_name, chart_config in all_charts.iteritems():
            jsdata_temp_file.write("    '%s': {\n" % chart_name)
            jsdata_temp_file.write("        'chart_title': '%s',\n" % chart_config["chart_title"])
            jsdata_temp_file.write("        'chart_series': [\n")
            for series in chart_config["chart_series"]:
                jsdata_temp_file.write("        {\n")
                metric_title = all_metrics[series["metric"]]["title"].replace("'", r"\'")
                jsdata_temp_file.write("            'name': '%s in %s',\n" % (metric_title, series["repo"]))
                jsdata_temp_file.write("            'color': '%s',\n" % series["color"])
                jsdata_temp_file.write("            'data': [")
                series_data = measured_data.get_repo_metric_dict(series["repo"], series["metric"])
                series_data = sorted(series_data.items(), key=lambda (sha1, datapoint): int(datapoint["timestamp"]))
                if not args.include_all_measured_sha1s:
                    repo_selected_sha1s = selected_commits[series["repo"]].values()
                    series_data = filter(lambda (sha1, datapoint): sha1 in repo_selected_sha1s, series_data)
                for idx, (sha1, datapoint) in enumerate(series_data):
                    if idx:
                        jsdata_temp_file.write("                     ")
                    jsdata_temp_file.write("{ 'x': %s, 'y': %s },\n" % (datapoint["timestamp"], datapoint["value"]))
                jsdata_temp_file.write("            ],\n")
                jsdata_temp_file.write("        },\n")
            jsdata_temp_file.write("        ],\n")
            jsdata_temp_file.write("        'chart_annotations': {\n")
            if "annotations" in chart_config:
                for annotation_set_name in chart_config["annotations"]:
                    annotations = config["annotation_sets"][annotation_set_name]
                    for date, description in annotations.iteritems():
                        timestamp = datetime.datetime.strptime(date, "%Y-%m-%d").strftime("%s")
                        jsdata_temp_file.write("        '%s': '%s',\n" % (timestamp, description))
            jsdata_temp_file.write("        },\n")
            jsdata_temp_file.write("    },\n")
        jsdata_temp_file.write("}\n")

        jsdata_temp_file.write("\n")
        jsdata_temp_file.write("timestamp_to_sha1 = {\n")
        for repo_name, repo_selected_commits in selected_commits.iteritems():
            for timestamp, sha1 in repo_selected_commits.iteritems():
                jsdata_temp_file.write("    %s: '%s',\n" % (timestamp, sha1))
        jsdata_temp_file.write("}\n")

    # when file is written, move it into place
    os.close(jsdata_tempfile_oshandle)
    shutil.move(jsdata_tempfile_name, jsdata_filename)
    os.chmod(jsdata_filename, stat.S_IRUSR | stat.S_IWUSR | stat.S_IROTH)

def refresh_measurements(config, data_filename, measured_data, jsdata_filename):
    selected_commits = {}
    for repo_name, repo_config in config["git_repos"].iteritems():
        if args.skip_fetch and not os.path.exists(local_workingdir(repo_config["git_url"])):
            print "ERROR: --skip-fetch cannot be used with repositories that hasn't been cloned yet. Please re-run without --skip-fetch."
            sys.exit(1)
        if not args.quiet:
            print >> sys.stderr, "Making list of SHA1s to measure in repo: " + repo_name
        selected_commits[repo_name] = get_sparse_commits(repo_name, repo_config)

    repo_to_metrics_map = {}
    for chart_name, chart in config["charts"].iteritems():
        for series in chart["chart_series"]:
            repo_to_metrics_map.setdefault(series["repo"], set()).add(series["metric"])

    todo_list = []
    for repo_name, repo_metrics in repo_to_metrics_map.iteritems():
        for timestamp, sha1 in selected_commits[repo_name].iteritems():
            metrics_that_lack_data_for_this_sha1 = []
            commit_timestamp = datetime.datetime.fromtimestamp(int(timestamp))
            for metric_name in repo_metrics:
                too_old = False
                metric_start_date = config["metrics"][metric_name].get("start_date", None)
                if metric_start_date:
                    too_old = commit_timestamp < datetime.datetime.strptime(metric_start_date, "%Y-%m-%d")

                if not too_old and not measured_data.is_measured(repo_name, sha1, metric_name):
                    metrics_that_lack_data_for_this_sha1.append(metric_name)
            if len(metrics_that_lack_data_for_this_sha1) > 0:
                todo_list.append((repo_name, sha1, timestamp, metrics_that_lack_data_for_this_sha1))

    random.shuffle(todo_list)

    for (repo_name, sha1, timestamp, metrics_that_lack_data_for_this_sha1) in todo_list:
        git_workdir = local_workingdir(config["git_repos"][repo_name]["git_url"])

        atleast_one_metric_needs_a_reset_workdir = False
        for metric_name in metrics_that_lack_data_for_this_sha1:
            if config["metrics"][metric_name].get("workdir", True):
                atleast_one_metric_needs_a_reset_workdir = True
                break

        if atleast_one_metric_needs_a_reset_workdir:
            git_reset_to(repo_name, git_workdir, sha1)

        for metric_name in metrics_that_lack_data_for_this_sha1:
            if not args.quiet:
                print >> sys.stderr, "%s: measuring %s (%s)" % (repo_name, sha1, metric_name)
            value = measure_metric(config["metrics"][metric_name], git_workdir, sha1, timestamp)
            measured_data.add_measurement(repo_name, sha1, timestamp, metric_name, value)

        measured_data.save_to_file(data_filename)
        save_data_jscopy(config, selected_commits, measured_data, jsdata_filename)
    else:
        save_data_jscopy(config, selected_commits, measured_data, jsdata_filename)


def main():
    config = eval(open(os.path.join(SCRIPT_DIR, "..", "config.pyon")).read())
    data_filename = os.path.join(SCRIPT_DIR, "..", "data.pyon")
    jsdata_filename = os.path.join(SCRIPT_DIR, "..", "all_chart_data.js")

    if os.path.exists(data_filename):
        measured_data = MeasuredData()
        measured_data.load_from_file(data_filename)
    else:
        measured_data = MeasuredData()

    if args.delete_data_for_repo:
        repo_name = args.delete_data_for_repo
        if not repo_name in config["git_repos"]:
            print "ERROR: no such repo name in config"
            sys.exit(1)
        measured_data.clear_data_for_repo(repo_name)
        measured_data.save_to_file(data_filename)
        print "All data for repo '%s' deleted." % repo_name
        sys.exit(0)

    if args.delete_data_for_metric:
        metric_name = args.delete_data_for_metric
        if not metric_name in config["metrics"]:
            print "ERROR: no such metric name in config"
            sys.exit(1)
        for repo_name, repo_config in config["git_repos"].iteritems():
            measured_data.clear_data_for_repo_metric(repo_name, metric_name)
        measured_data.save_to_file(data_filename)
        print "All data for metric '%s' deleted." % metric_name
        sys.exit(0)

    if args.list_repos:
        for repo_name in config["git_repos"]:
            print repo_name
        sys.exit(0)

    if args.list_metrics:
        for metric_name in config["metrics"]:
            print metric_name
        sys.exit(0)

    if not args.skip_fetch:
        git_urls = [repo["git_url"] for (_, repo) in config["git_repos"].iteritems()]
        fetch_latest_code(git_urls)

    refresh_measurements(config, data_filename, measured_data, jsdata_filename)

if __name__ == '__main__':
    try:
        parser = argparse.ArgumentParser()
        parser.add_argument("--quiet", action="store_true")
        parser.add_argument("--debug", action="store_true")

        parser.add_argument("--skip-fetch", action="store_true", help="don't call 'git fetch', just process what is available locally (for debugging only)")

        # Ignoring commits before year 1990 because golang repo starts with a
        # few prank commits from the 70ties and this compressed the meaningful
        # data visually in the finished chart.
        parser.add_argument("--ignore-commits-before-year", metavar="YYYY", type=int, default=1990)

        parser.add_argument("--include-all-measured-sha1s", action="store_true")

        parser.add_argument("--delete-data-for-metric", metavar="METRIC_NAME", type=str)
        parser.add_argument("--delete-data-for-repo", metavar="REPO_NAME", type=str)
        parser.add_argument("--list-repos", action="store_true")
        parser.add_argument("--list-metrics", action="store_true")
        args = parser.parse_args()
        main()
    except KeyboardInterrupt:
        print
        pass
