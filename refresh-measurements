#!/usr/bin/env python

import os
import stat
import random
import pprint
import argparse
import datetime
import subprocess

SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
CONFIG_DIR = "~/.git-source-metrics/"
CODE_CACHE_DIR = "~/.git-source-metrics/code/"

def local_workingdir(git_repo):
    code_cache_dir = os.path.expanduser(CODE_CACHE_DIR)
    if not os.path.exists(code_cache_dir):
        os.makedirs(code_cache_dir)
    working_dirname = filter(str.isalnum, git_repo)
    working_dir_path = os.path.join(code_cache_dir, working_dirname)
    return working_dir_path

def fetch_latest_code(git_repo):
    git_workdir = local_workingdir(git_repo)
    if not os.path.exists(git_workdir):
        subprocess.check_call("git clone %s %s" % (git_repo, git_workdir), shell=True)
    else:
        subprocess.check_call("git fetch -q", cwd=git_workdir, shell=True)

def git_reset_to(git_workdir, sha1):
    subprocess.check_call("git clean -dxff", cwd=git_workdir, shell=True)
    subprocess.check_call("git reset -q --hard %s" % sha1, cwd=git_workdir, shell=True)

def get_sparse_commits(git_workdir, gap_days):
    git_reset_to(git_workdir, "origin/master")
    git_log_cmd = "git log --first-parent --pretty=format:'%H %ct'"
    git_log_output = subprocess.check_output(git_log_cmd, cwd=git_workdir, shell=True)
    sha1_and_timestamp_list = git_log_output.splitlines()

    all_xtick_sha1s = []
    last_tick_commit_date = datetime.datetime.utcfromtimestamp(0)

    while len(sha1_and_timestamp_list) > 0:
        sha1, timestamp = sha1_and_timestamp_list.pop(-1).split(" ", 1)
        if not timestamp:
            if not args.quiet:
                # Happens for 281a10c59d5a6522b2bebc6f78c165816d1f8421 in https://github.com/mozilla/gecko-dev
                # Not sure if this is a git bug or not, I couldn't find a way to create a commit with empty
                # author name (like the one above) so maybe it's a bug in the mercurial to git conversion tool
                # that mozilla uses.
                print "WARNING: commit with sha1 %s looks invalid, ignoring." % sha1
            continue
        commit_date = datetime.datetime.fromtimestamp(int(timestamp))
        if commit_date < last_tick_commit_date:
            if not args.quiet:
                print "WARNING: commit with sha1 %s has commit date which is earlier than the commit date of its first parent, which is kind of weird; ignoring." % sha1
            continue
        if (commit_date - last_tick_commit_date).days >= gap_days:
            all_xtick_sha1s.append((sha1, timestamp))
            last_tick_commit_date = commit_date

    return all_xtick_sha1s

def measure_metric(metric, git_workdir):
    return int(subprocess.check_output(metric["cmd"], cwd=git_workdir, shell=True).strip())

class MeasuredData(object):
    def __init__(self):
        self.metric_datapoints = {}

    def load_from_file(self, filename):
        self.metric_datapoints = eval(open(filename).read())

    def save_to_file(self, filename):
        string_data = pprint.pformat(self.metric_datapoints)
        file_dir = os.path.dirname(filename)
        if not os.path.exists(file_dir):
            os.makedirs(file_dir)
        with open(filename, "w") as fil:
            fil.write(string_data)

    def get_metric_data(self, metric_name):
        return self.metric_datapoints.setdefault(metric_name, {})

    def is_measured(self, metric_name, sha1):
        return sha1 in self.get_metric_data(metric_name)

    def add_measurement(self, metric_name, sha1, timestamp, value):
        datapoint = {
            "sha1": sha1,
            "timestamp": timestamp,
            "value": value,
        }
        metric_data = self.get_metric_data(metric_name)
        metric_data[sha1] = datapoint

def save_data_jscopy(all_dataset_configs, selected_commits, measured_data, jsdata_filename):
    with open(jsdata_filename, "w") as jsdatafile:
        jsdatafile.write("jsdata = {\n")
        selected_sha1s = [sha1 for (sha1, timestamp) in selected_commits]
        for dataset_name, dataset_config in all_dataset_configs.iteritems():
            jsdatafile.write("    '%s': {\n" % dataset_name)
            jsdatafile.write("        'title': '%s',\n" % dataset_config["title"])
            jsdatafile.write("        'series': [\n")
            for metric in dataset_config["metrics"]:
                series_data = measured_data.get_metric_data(metric["name"])
                jsdatafile.write("        {\n")
                jsdatafile.write("            'metric': '%s',\n" % metric["name"])
                jsdatafile.write("            'name': '%s',\n" % metric["title"].replace("'", r"\'"))
                jsdatafile.write("            'data': [")
                series_data = sorted(series_data.items(), key=lambda (sha1, datapoint): datapoint["timestamp"])
                series_data = filter(lambda (sha1, datapoint): sha1 in selected_sha1s, series_data)
                for idx, (sha1, datapoint) in enumerate(series_data):
                    if idx:
                        jsdatafile.write("                     ")
                    jsdatafile.write("{ 'x': %s, 'y': %s },\n" % (datapoint["timestamp"], datapoint["value"]))
                jsdatafile.write("            ],\n")
                jsdatafile.write("            'color': '%s',\n" % metric["color"])
                jsdatafile.write("        },\n")
            jsdatafile.write("        ],\n")
            jsdatafile.write("    },\n")
        jsdatafile.write("}\n")

        jsdatafile.write("\n")
        jsdatafile.write("timestamp_to_sha1 = {\n")
        if len(selected_commits) > 0:
            for sha1, timestamp in selected_commits:
                jsdatafile.write("    %s: '%s',\n" % (timestamp, sha1))
        jsdatafile.write("}\n")

    os.chmod(jsdata_filename, stat.S_IRUSR | stat.S_IWUSR | stat.S_IROTH)

def main():
    config = eval(open(os.path.join(SCRIPT_DIR, "..", "config.pyon")).read())

    jsdata_filename = os.path.join(SCRIPT_DIR, "..", "data", "jsdata.js")

    data_filename = os.path.join(SCRIPT_DIR, "..", "data", "data.pyon")
    if os.path.exists(data_filename):
        measured_data = MeasuredData()
        measured_data.load_from_file(data_filename)
    else:
        measured_data = MeasuredData()

    fetch_latest_code(config["git_repo"])
    git_workdir = local_workingdir(config["git_repo"])
    selected_commits = get_sparse_commits(git_workdir, config["tick_gap_days"])

    todo_list = []
    for sha1, timestamp in selected_commits:
        metrics_that_lack_data_for_this_sha1 = []
        for dataset_name, dataset_config in config["datasets"].iteritems():
            for metric in dataset_config["metrics"]:
                if not measured_data.is_measured(metric["name"], sha1):
                    metrics_that_lack_data_for_this_sha1.append(metric)
        if len(metrics_that_lack_data_for_this_sha1) > 0:
            todo_list.append((sha1, timestamp, metrics_that_lack_data_for_this_sha1))

    random.shuffle(todo_list)

    for (sha1, timestamp, metrics_that_lack_data_for_this_sha1) in todo_list:
        git_reset_to(git_workdir, sha1)

        for metric in metrics_that_lack_data_for_this_sha1:
            if not args.quiet:
                print "measuring: %s (%s)" % (sha1, metric["name"])
            value = measure_metric(metric, git_workdir)
            measured_data.add_measurement(metric["name"], sha1, timestamp, value)

        measured_data.save_to_file(data_filename)
        save_data_jscopy(config["datasets"], selected_commits, measured_data, jsdata_filename)

    else:
        save_data_jscopy(config["datasets"], selected_commits, measured_data, jsdata_filename)

if __name__ == '__main__':
    try:
        parser = argparse.ArgumentParser()
        parser.add_argument("--quiet", action="store_true")
        args = parser.parse_args()
        main()
    except KeyboardInterrupt:
        print
        pass
